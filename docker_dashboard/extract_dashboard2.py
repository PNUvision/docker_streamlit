import streamlit as st
import pandas as pd
import numpy as np
import os
import zipfile
import io
import matplotlib.pyplot as plt
from scipy.signal import correlate
# import pdb

import plotly.graph_objects as go
from plotly.subplots import make_subplots

from matplotlib import font_manager, rc
font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)  
plt.rcParams['axes.unicode_minus'] = False



st.set_page_config(layout="wide")  # ë„“ì€ ë ˆì´ì•„ì›ƒ

# ---------- í•¨ìˆ˜ ì •ì˜ ----------
def normalized_cross_correlation(data, template):
    data_mean = np.mean(data)
    template_mean = np.mean(template)
    data_normalized = data - data_mean
    template_normalized = template - template_mean
    correlation = correlate(data_normalized, template_normalized, mode='valid')
    data_std = np.std(data)
    template_std = np.std(template)
    ncc = correlation / (data_std * template_std * len(template))
    return ncc

def group_consecutive(values, max_diff=50):
    if len(values) == 0:
        return []
    values = sorted(values)
    groups = []
    group = [values[0]]
    for current, next_ in zip(values, values[1:]):
        if next_ <= current + max_diff:            
            group.append(next_)
        else:
            groups.append(group)
            group = [next_]
    groups.append(group)
    return groups

# ---------- ë°ì´í„° ë¡œë”© ----------
st.title("ğŸš€ ì‹ í˜¸ ë§¤ì¹˜ ë° ì¶”ì¶œ ì•±")


# ì‚¬ìš©ìë¡œë¶€í„° feather íŒŒì¼ ì—…ë¡œë“œ ë°›ê¸°
uploaded_file = st.file_uploader("ğŸ“‚ Feather (.ftr) íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=["ftr"])

if uploaded_file is not None:
    try:
        # ì—…ë¡œë“œëœ feather íŒŒì¼ ì½ê¸°
        first_df = pd.read_feather(uploaded_file)
        cp_df = first_df.copy()
        # print(cp_df.head())
        
        # ì‚¬ìš©ìê°€ ë°ì´í„° ì†ì„±ì„ ì„ íƒí•  ìˆ˜ ìˆëŠ” ë“œë¡­ë‹¤ìš´ ë©”ë‰´ ì¶”ê°€
        selected_column = st.selectbox(
            "ë§¤ì¹­í•  ì‹ í˜¸ ë°ì´í„° ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”:",
            options=cp_df.columns.tolist(),
            index=cp_df.columns.tolist().index('GT FUEL CONSUMPTION') if 'GT FUEL CONSUMPTION' in cp_df.columns else 0
        )
        
        # ì„ íƒí•œ ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if selected_column in cp_df.columns:
            signal = cp_df[selected_column].values
            st.success(f"âœ… '{selected_column}' ì»¬ëŸ¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.error(f"â— '{selected_column}' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            st.stop()

    except Exception as e:
        st.error(f"â— íŒŒì¼ì„ ì½ëŠ” ë„ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()

else:
    st.warning("â³ Feather íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.stop()
# ------------------------------


# ì‚¬ì´ë“œë°” ìµœìƒë‹¨: í…œí”Œë¦¿ ì—…ë¡œë“œ
st.sidebar.markdown("ğŸ§¬ **Template íŒŒì¼ ì—…ë¡œë“œ (.npy)**")

uploaded_template_1 = st.sidebar.file_uploader("ğŸ“‚ ê¸°ë™ ì‹œì‘ í…œí”Œë¦¿ (Template 1)", type=["npy"], key="t1")
uploaded_template_2 = st.sidebar.file_uploader("ğŸ“‚ ê¸°ë™ ì¢…ë£Œ í…œí”Œë¦¿ (Template 2)", type=["npy"], key="t2")

# ê¸°ë³¸ê°’ìœ¼ë¡œ ë¡œë“œ
template_1 = np.load('fuel_temp_st.npy')
template_2 = np.load('fuel_temp_et.npy')

# ì—…ë¡œë“œê°€ ìˆë‹¤ë©´ ë®ì–´ì“°ê¸°
if uploaded_template_1 is not None:
    try:
        template_1 = np.load(uploaded_template_1)
        st.sidebar.success("âœ… Template 1 ì—…ë¡œë“œ ì™„ë£Œ")
    except:
        st.sidebar.error("â— Template 1 ë¡œë“œ ì‹¤íŒ¨")

if uploaded_template_2 is not None:
    try:
        template_2 = np.load(uploaded_template_2)
        st.sidebar.success("âœ… Template 2 ì—…ë¡œë“œ ì™„ë£Œ")
    except:
        st.sidebar.error("â— Template 2 ë¡œë“œ ì‹¤íŒ¨")


# ------------------------------------------------------------------------------------------
# ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬
def preprocess_signal(signal2):
    # NaN ë° Inf ê°’ í™•ì¸
    nan_mask = np.isnan(signal2)
    inf_mask = np.isinf(signal2)
    
    if np.any(nan_mask) or np.any(inf_mask):
        print(f"Found {np.sum(nan_mask)} NaN values and {np.sum(inf_mask)} Inf values")
        
        # NaN/Inf ê°’ ì œê±°ë¥¼ ìœ„í•œ ë³µì‚¬ë³¸ ìƒì„±
        clean_signal = signal2.copy()
        
        # ë‹¨ìˆœí•œ ë°©ë²•: NaN ë° Inf ê°’ì„ ì´ì›ƒ ê°’ì˜ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
        bad_indices = np.where(nan_mask | inf_mask)[0]
        for idx in bad_indices:
            # ì¢Œìš° 10ê°œ ìƒ˜í”Œ ë‚´ì—ì„œ ìœ íš¨í•œ ê°’ì„ ì°¾ì•„ í‰ê·  ê³„ì‚°
            window_start = max(0, idx - 10)
            window_end = min(len(signal2), idx + 11)
            window = signal2[window_start:window_end]
            valid_values = window[~(np.isnan(window) | np.isinf(window))]
            
            if len(valid_values) > 0:
                clean_signal[idx] = np.mean(valid_values)
            else:
                # ì£¼ë³€ì— ìœ íš¨í•œ ê°’ì´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ëŒ€ì²´
                clean_signal[idx] = 0
        
        return clean_signal
    
    return signal2

# ì „ì²˜ë¦¬ ì ìš©
signal = preprocess_signal(signal)
template_1 = preprocess_signal(template_1)
template_2 = preprocess_signal(template_2)
# ------------------------------------------------------------------------------------------


# ---------- ì‚¬ìš©ì ì…ë ¥ ----------
st.sidebar.header("ğŸ”§ ë§¤ì¹˜ ì„¤ì •")
with st.sidebar:
    st.markdown("ğŸ“‰ **Template 1 (ê¸°ë™ ì‹œì‘)**")
    fig_t1, ax1 = plt.subplots(figsize=(3, 1.5))
    ax1.plot(template_1, linewidth=0.8)
    # ax1.set_xticks([]), ax1.set_yticks([])
    ax1.set_title("ì‹œì‘ í…œí”Œë¦¿", fontsize=10)
    st.pyplot(fig_t1)
    plt.close(fig_t1)

    st.markdown("ğŸ“ˆ **Template 2 (ê¸°ë™ ì¢…ë£Œ)**")
    fig_t2, ax2 = plt.subplots(figsize=(3, 1.5))
    ax2.plot(template_2, linewidth=0.8, color='orange')
    # ax2.set_xticks([]), ax2.set_yticks([])
    ax2.set_title("ì¢…ë£Œ í…œí”Œë¦¿", fontsize=10)
    st.pyplot(fig_t2)
    plt.close(fig_t2)

    st.markdown("---")


with st.sidebar:
    st.header("ğŸ”„ ë§¤ì¹­ê¸° ì„¤ì •")
    max_diff = st.selectbox(
        "ì—°ì†ìœ¼ë¡œ ê°„ì£¼í•  ìµœëŒ€ ì°¨ì´ê°’",
        options=[1, 10, 50, 100, 200, 500, 1000],
        index=2,  # ê¸°ë³¸ê°’ì„ 50ìœ¼ë¡œ ì„¤ì • (index 2)
        help="ë‘ ê°’ ì‚¬ì´ì˜ ì°¨ì´ê°€ ì´ ê°’ ì´í•˜ì´ë©´ ì—°ì†ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤."
    )
    st.markdown("---")



# ---------- ì‚¬ìš©ì ì…ë ¥ ----------
with st.sidebar:
    st.markdown("ğŸ§  **íšŒì‚¬ëª…:** ãˆœíŒŒì‹œë””ì—˜")
    st.markdown("ğŸ« **ì—°êµ¬ì‹¤:** VisLAB PNU")
    st.markdown("ğŸ‘¨â€ğŸ’» **ì œì‘ì:** (C) DJKang")
    st.markdown("ğŸ› ï¸ **ë²„ì „:** V.1.0 (04-22-2025)")
    st.markdown("---")


with st.form(key="matching_form"):
    st_thres = st.slider("ê¸°ë™ ì‹œì‘ NCC Threshold", 0.0, 1.0, 0.2, 0.01)
    st_low = st.number_input("ê¸°ë™ ì‹œì‘ ì‹ í˜¸ ìµœì†Œê°’", value=0.0)
    st_high = st.number_input("ê¸°ë™ ì‹œì‘ ì‹ í˜¸ ìµœëŒ€ê°’", value=1.0)
    offset_1 = st.number_input("ê¸°ë™ ì‹œì‘ offset", value=1000)

    et_thres = st.slider("ê¸°ë™ ì¢…ë£Œ NCC Threshold", 0.0, 1.0, 0.2, 0.01)
    et_low = st.number_input("ê¸°ë™ ì¢…ë£Œ ì‹ í˜¸ ìµœì†Œê°’", value=5.0)
    et_high = st.number_input("ê¸°ë™ ì¢…ë£Œ ì‹ í˜¸ ìµœëŒ€ê°’", value=8.0)
    offset_2 = st.number_input("ê¸°ë™ ì¢…ë£Œ offset", value=800)

    remove_st_idx = st.text_input("ê¸°ë™ ì‹œì‘ë¶€ ì œê±°í•  ê·¸ë£¹ ì¸ë±ìŠ¤ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value="0,5,17")
    remove_et_idx = st.text_input("ê¸°ë™ ì¢…ë£Œë¶€ ì œê±°í•  ê·¸ë£¹ ì¸ë±ìŠ¤ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value="")

    submitted = st.form_submit_button("â–¶ï¸ ë§¤ì¹˜ ìˆ˜í–‰")

if submitted:
    # ---------- ì‹œì‘ë¶€ ë§¤ì¹­ ----------
    # ncc_start[0]ì€ í…œí”Œë¦¿ì´ signal[0:20]ê³¼ ì •ë ¬ë  ë•Œì˜ ìƒê´€ê´€ê³„ ê°’
    # ncc_start[10]ì€ í…œí”Œë¦¿ì´ signal[10:30]ê³¼ ì •ë ¬ë  ë•Œì˜ ìƒê´€ê´€ê³„ ê°’
    ncc_start = normalized_cross_correlation(signal, template_1)
    # true_idx_st = np.where((ncc_start > st_thres) & (signal[:len(ncc_start)] > st_low) & (signal[:len(ncc_start)] < st_high))[0]
    st_ncc_above_threshold = np.where(ncc_start > st_thres)[0]
    # ê·¸ ì¸ë±ìŠ¤ì—ì„œ signal ê°’ì´ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤
    true_idx_st = st_ncc_above_threshold[
        (signal[st_ncc_above_threshold] > st_low) & 
        (signal[st_ncc_above_threshold] < st_high)
    ]    
    st_groups = group_consecutive(true_idx_st)

    for idx in sorted([int(i) for i in remove_st_idx.split(',') if i.strip().isdigit()], reverse=True):
        if 0 <= idx < len(st_groups):
            del st_groups[idx]

    means_start = [np.mean(signal[grp]) for grp in st_groups]
    st.subheader(f"ğŸŸ¢ ê¸°ë™ ì‹œì‘: ê·¸ë£¹ ìˆ˜ = {len(st_groups)}")
    with st.expander("ê¸°ë™ ì‹œì‘ ê·¸ë£¹ í‰ê· ê°’ (ì „ì²´ í‘œì‹œ)", expanded=True):
        st.markdown(
            f"<div style='max-height: 300px; overflow-y: auto; border:1px solid #ccc; padding:10px;'>"
            + "<br>".join([f"ê·¸ë£¹ {i}: í‰ê·  = {v:.4f}" for i, v in enumerate(means_start)])
            + "</div>",
            unsafe_allow_html=True
        )

    # ---------- ì¢…ë£Œë¶€ ë§¤ì¹­ ----------
    ncc_end = normalized_cross_correlation(signal, template_2)
    # true_idx_et = np.where((ncc_end > et_thres) & (signal[:len(ncc_end)] > et_low) & (signal[:len(ncc_end)] < et_high))[0]
    et_ncc_above_threshold = np.where(ncc_end > et_thres)[0]
    true_idx_et = et_ncc_above_threshold[
        (signal[et_ncc_above_threshold] > et_low) & 
        (signal[et_ncc_above_threshold] < et_high)
    ]    
    et_groups = group_consecutive(true_idx_et)

    for idx in sorted([int(i) for i in remove_et_idx.split(',') if i.strip().isdigit()], reverse=True):
        if 0 <= idx < len(et_groups):
            del et_groups[idx]

    means_end = [np.mean(signal[grp]) for grp in et_groups]
    st.subheader(f"ğŸ”´ ê¸°ë™ ì¢…ë£Œ: ê·¸ë£¹ ìˆ˜ = {len(et_groups)}")
    with st.expander("\ud68c\ubcf5 \uc885\ub8cc \ud3c9\uade0\uac12 (ì „ì²´ í‘œì‹œ)", expanded=True):
        st.markdown(
            f"<div style='max-height: 300px; overflow-y: auto; border:1px solid #ccc; padding:10px;'>"
            + "<br>".join([f"ê·¸ë£¹ {i}: í‰ê·  = {v:.4f}" for i, v in enumerate(means_end)])
            + "</div>",
            unsafe_allow_html=True
        )


    # -------------------------------------------------------------------
    # ìƒ˜í”Œë§ ë¹„ìœ¨ ì„ íƒ ìœ„ì ¯ ì¶”ê°€ (ê¸°ë³¸ê°’: 10)
    sampling_rate = st.slider("ìƒ˜í”Œë§ ë¹„ìœ¨ ì„ íƒ", min_value=1, max_value=50, value=10, step=1)

    # ì‹ í˜¸ ìƒ˜í”Œë§ í•¨ìˆ˜ ì •ì˜
    def downsample(data, rate):
        return data[::rate]

    # ìƒ˜í”Œë§ëœ ì‹ í˜¸ì™€ ì¸ë±ìŠ¤ ìƒì„±
    sampled_signal = downsample(signal, sampling_rate)
    sampled_indices = list(range(0, len(signal), sampling_rate))

    # ê¸°ë™ ì‹œì‘ ë§¤ì¹­ ì‹œê°í™”
    fig1 = go.Figure()

    # ë©”ì¸ ì‹ í˜¸ í”Œë¡¯ (ìƒ˜í”Œë§ ì ìš©)
    fig1.add_trace(
        go.Scatter(
            x=sampled_indices,
            y=sampled_signal,
            mode='lines',
            name='Signal',
            line=dict(color='blue', width=1)
        )
    )

    # ë§¤ì¹­ ìœ„ì¹˜ í‘œì‹œ (ìƒ˜í”Œë§ ì ìš©í•˜ì§€ ì•ŠìŒ - ì •í™•í•œ ìœ„ì¹˜ ìœ ì§€)
    for i, grp in enumerate(st_groups):
        x = grp[0] - offset_1
        fig1.add_trace(
            go.Scatter(
                x=[x, x],
                y=[min(sampled_signal), max(sampled_signal)],
                mode='lines',
                name=f'Match {i}',
                line=dict(color='red', width=1, dash='dash')
            )
        )
        # í…ìŠ¤íŠ¸ ë ˆì´ë¸” ì¶”ê°€
        fig1.add_annotation(
            x=x,
            y=max(sampled_signal) * 0.9,
            text=f"{i}",
            showarrow=False,
            font=dict(color='red', size=15)
        )

    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig1.update_layout(
        title=f'Template 1 Matching (Start) - ìƒ˜í”Œë§ ë¹„ìœ¨: 1/{sampling_rate}',
        xaxis_title='Sample Index',
        yaxis_title='Signal Value',
        height=600,
        hovermode='closest',
        showlegend=False
    )

    # í”Œë¡¯ í‘œì‹œ
    st.plotly_chart(fig1, use_container_width=True)

    # ê¸°ë™ ì¢…ë£Œ ë§¤ì¹­ ì‹œê°í™”
    fig2 = go.Figure()

    # ë©”ì¸ ì‹ í˜¸ í”Œë¡¯ (ìƒ˜í”Œë§ ì ìš©)
    fig2.add_trace(
        go.Scatter(
            x=sampled_indices,
            y=sampled_signal,
            mode='lines',
            name='Signal',
            line=dict(color='blue', width=1)
        )
    )

    # ë§¤ì¹­ ìœ„ì¹˜ í‘œì‹œ (ìƒ˜í”Œë§ ì ìš©í•˜ì§€ ì•ŠìŒ - ì •í™•í•œ ìœ„ì¹˜ ìœ ì§€)
    for i, grp in enumerate(et_groups):
        x = grp[0] + offset_2
        fig2.add_trace(
            go.Scatter(
                x=[x, x],
                y=[min(sampled_signal), max(sampled_signal)],
                mode='lines',
                name=f'Match {i}',
                line=dict(color='red', width=1, dash='dash')
            )
        )
        # í…ìŠ¤íŠ¸ ë ˆì´ë¸” ì¶”ê°€
        fig2.add_annotation(
            x=x,
            y=max(sampled_signal) * 0.9,
            text=f"{i}",
            showarrow=False,
            font=dict(color='red', size=15)
        )

    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig2.update_layout(
        title=f'Template 2 Matching (End) - ìƒ˜í”Œë§ ë¹„ìœ¨: 1/{sampling_rate}',
        xaxis_title='Sample Index',
        yaxis_title='Signal Value',
        height=600,
        hovermode='closest',
        showlegend=False
    )

    # í”Œë¡¯ í‘œì‹œ
    st.plotly_chart(fig2, use_container_width=True)
    # -------------------------------------------------------------------


# ---- 1. ì¶”ì¶œ ì‹¤í–‰ ë²„íŠ¼ ìƒíƒœ ê´€ë¦¬ ----
if "run_extraction" not in st.session_state:
    st.session_state.run_extraction = False

if st.button("âœ‚ï¸ ê¸°ë™ ì‹ í˜¸ ì¶”ì¶œ ë° ì‹œê°í™”"):
    st.session_state.run_extraction = True

# ---- 2. ì¶”ì¶œ ì‹¤í–‰ ì¡°ê±´ (ì œì¶œ ì™„ë£Œ í›„, ë³„ë„ ì‹¤í–‰) ----
if st.session_state.run_extraction:
    if 'st_groups' not in locals() or 'et_groups' not in locals():
        st.warning("ë¨¼ì € ì¢Œì¸¡ì—ì„œ ë§¤ì¹˜ ìˆ˜í–‰ í›„ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    elif len(st_groups) == 0 or len(et_groups) == 0:
        st.warning("ì‹œì‘ ë˜ëŠ” ì¢…ë£Œ ê·¸ë£¹ì´ ë¹„ì–´ ìˆì–´ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.success("âœ… ì¶”ì¶œ ë° ì‹œê°í™” ì‹¤í–‰ ì¤‘...")
        pairs = []
        for st_grp, et_grp in zip(st_groups, et_groups):
            st_pt = max(0, st_grp[0] - offset_1)
            et_pt = min(len(signal), et_grp[0] + offset_2)
            if st_pt < et_pt:
                pairs.append((st_pt, et_pt))

        st.write(f"ì´ ì¶”ì¶œ êµ¬ê°„ ìˆ˜: {len(pairs)}")


        # âœ… ì¶”ê°€ëœ ì½”ë“œ
        # save_folder = "saved_crops"  # dockerì—ì„œëŠ” /appë¡œ
        saved_root = "/app/data" if os.path.exists("/app/data") else os.getcwd()
        save_folder = os.path.join(saved_root, 'saved_crops')
        os.makedirs(save_folder, exist_ok=True)

        for i, (st_pt, et_pt) in enumerate(pairs):
            # 1. ë‹¤ë³€ëŸ‰ crop
            crop_df = cp_df.iloc[st_pt:et_pt]  # ëª¨ë“  ì»¬ëŸ¼ì— ëŒ€í•´ crop

            # 2. numpyë¡œ ë³€í™˜
            crop_np = crop_df.to_numpy()  # shape: (crop_len, feature_dim)

            # crop_np.head()
            # 3. ì €ì¥ íŒŒì¼ëª… ìƒì„± (ë‚ ì§œ+ì‹œê°„ ê¸°ë°˜)
            if 'timestamp' in crop_df.columns:  # 'timestamp' ì»¬ëŸ¼ì´ datetime í˜•íƒœë¼ë©´
                # st_pt ìœ„ì¹˜ì˜ ë‚ ì§œ/ì‹œê°„ì„ ê¸°ë°˜ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±
                timestamp = pd.to_datetime(crop_df['timestamp'].iloc[0])
                timestamp_str = timestamp.strftime("%Y%m%d_%H%M%S")
            else:
                timestamp_str = f"crop_{i}"

            save_path = os.path.join(save_folder, f"{timestamp_str}_crop.npy")

            # 4. npy ì €ì¥
            np.save(save_path, crop_np)

            # 5. crop ì‹œê°í™” (íŠ¹ì§• í•˜ë‚˜ë§Œ ê°„ë‹¨íˆ ì˜ˆì‹œ)
            fig_crop, ax_crop = plt.subplots(figsize=(8, 3))
            # ax_crop.plot(crop_df.iloc[:, 0])   
            ax_crop.plot(signal[st_pt:et_pt])   
            ax_crop.set_title(f"ì¶”ì¶œ ì‹ í˜¸ {i} (len={len(crop_df)})")
            st.pyplot(fig_crop)
            plt.close(fig_crop)

            st.info(f"âœ… Saved: {save_path}")        


        # ğŸ‘‰ ì¶”ì¶œ ì™„ë£Œ í›„ ìë™ ë¦¬ì…‹ (ì„ íƒ)
        st.session_state.run_extraction = False


# ====================================================================== 
# ì„œë²„ì˜ /app/dataì— ì €ì¥ëœ npyíŒŒì¼ë“¤ì„ clientë¡œ ì••ì¶•í•´ì„œ ë‹¤ìš´ë¡œë“œ
def get_npy_files_in_data_dir():
    """
    ì»¨í…Œì´ë„ˆ ë‚´ì˜ /app/data ë””ë ‰í† ë¦¬ì— ìˆëŠ” ëª¨ë“  .npy íŒŒì¼ ì°¾ê¸°
    (ì´ ë””ë ‰í† ë¦¬ëŠ” í˜¸ìŠ¤íŠ¸ì˜ /home/pashidl/streamlit/dashboardì— ë§¤í•‘ë¨)
    """
    default_root = "/app/data" if os.path.exists("/app/data") else os.getcwd()
    data_dir = os.path.join(default_root, 'saved_crops')
    # data_dir = "/app/data"
    npy_files = []
    
    # ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  .npy íŒŒì¼ ì°¾ê¸°
    for file in os.listdir(data_dir):
        if file.endswith(".npy"):
            npy_files.append(os.path.join(data_dir, file))
    
    return npy_files

def create_download_link_for_all_files(npy_files):
    """ëª¨ë“  .npy íŒŒì¼ì„ zipìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±"""
    # ë©”ëª¨ë¦¬ì— ZIP íŒŒì¼ ìƒì„±
    zip_buffer = io.BytesIO()
    
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for file_path in npy_files:
            file_name = os.path.basename(file_path)
            # ê° .npy íŒŒì¼ì„ zipì— ì¶”ê°€
            zip_file.write(file_path, file_name)
    
    zip_buffer.seek(0)
    
    # ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
    st.download_button(
        label="ëª¨ë“  NPY íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
        data=zip_buffer,
        file_name="all_npy_files.zip",
        mime="application/zip"
    )

# ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ì„ UIì— ì¶”ê°€
st.header("NPY íŒŒì¼ ë‹¤ìš´ë¡œë“œ")

# ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
if st.button("NPY íŒŒì¼ ê²€ìƒ‰ ë° ë‹¤ìš´ë¡œë“œ ì¤€ë¹„"):
    # ë²„íŠ¼ì´ í´ë¦­ë˜ì—ˆì„ ë•Œë§Œ ì•„ë˜ ì½”ë“œ ì‹¤í–‰
    
    # .npy íŒŒì¼ ì°¾ê¸°
    npy_files = get_npy_files_in_data_dir()
    
    if not npy_files:
        st.warning("ë””ë ‰í† ë¦¬ì— .npy íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # íŒŒì¼ ëª©ë¡ í‘œì‹œ
        st.write(f"ì´ {len(npy_files)}ê°œì˜ .npy íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:")
        
        # íŒŒì¼ ëª©ë¡ì„ í‘œì‹œ
        for file_path in npy_files:
            file_name = os.path.basename(file_path)
            file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB ë‹¨ìœ„ë¡œ ë³€í™˜
            st.write(f"- **{file_name}** ({file_size:.2f} MB)")
        
        # êµ¬ë¶„ì„  ì¶”ê°€
        st.divider()
        
        # ì „ì²´ íŒŒì¼ ZIPìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ì˜µì…˜
        create_download_link_for_all_files(npy_files)